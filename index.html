<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>QAM's Learning Materials</title>
</head>
<body>
    <h1>Machine Learning</h1>

    <!-- First Block of List -->
    <div>
        <h2>LLM / Prompt</h2>
        <ul>
            <li><a href="https://arxiv.org/abs/2205.13147" target="_blank">Matryoshka Representation Learning</a></li>
            <li><a href="https://arxiv.org/abs/2407.20798" target="_blank">Diffusion Augmented Agents: A Framework for Efficient Exploration and Transfer Learning</a></li>
            <li><a href="https://arxiv.org/abs/2407.12994" target="_blank">A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks</a></li>
        </ul>
    </div>

    <!-- Second Block of List -->
    <div>
        <h2>Retrieval-Augmented Generation</h2>
        <ul>
            <li><a href="https://arxiv.org/abs/2402.14207" target="_blank">Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models</a></li>
            <li><a href="https://arxiv.org/abs/2407.16833" target="_blank">Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach</a></li>
            <li><a href="https://arxiv.org/abs/2407.01219" target="_blank">Searching for Best Practices in Retrieval-Augmented Generation</a></li>
            <li><a href="https://arxiv.org/abs/2406.17419" target="_blank">Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA</a></li>
        </ul>
    </div>

    <!-- Third Block of List -->
    <div>
        <h2>Optimize / Fine tune model</h2>
        <ul>
            <li><a href="https://arxiv.org/abs/2407.14679" target="_blank">Compact Language Models via Pruning and Knowledge Distillation</a></li>
            <li><a href="https://arxiv.org/abs/2407.16216" target="_blank">A Comprehensive Survey of LLM Alignment Techniques: RLHF, RLAIF, PPO, DPO and More</a></li>
            <li><a href="https://arxiv.org/abs/2405.12130" target="_blank">MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning</a></li>
            <li><a href="https://arxiv.org/abs/2304.11277" target="_blank">PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel</a></li>
            <li><a href="https://research.character.ai/optimizing-inference/" target="_blank">Optimizing AI Inference at Character.AI</a></li>
        </ul>
    </div>

    <!-- Fourth Block of List -->
    <div>
        <h2>Other</h2>
        <ul>
            <li><a href="https://arxiv.org/abs/2408.14837" target="_blank">Diffusion Models Are Real-Time Game Engines</a></li>
        </ul>
    </div>
</body>
</html>
