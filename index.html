<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>QAM's Learning Materials</title>
</head>
<body>
    <h1>Machine Learning</h1>

    <!-- First Block of List -->
    <div>
        <h2>LLM / MLLM / Prompt</h2>
        <ul>
            <li><a href="https://arc.net/folder/D0472A20-9C20-4D3F-B145-D2865C0A9FEE" target="_blank">Ilya suggested papers</a></li>
            <li><a href="https://www.youtube.com/watch?v=quh7z1q7-uc" target="_blank">(Youtube) Building LLMs from the Ground Up: A 3-hour Coding Workshop</a></li>
            <li><a href="https://arxiv.org/abs/2409.02060" target="_blank">OLMoE: Open Mixture-of-Experts Language Models</a></li>
            <li><a href="https://arxiv.org/abs/2205.13147" target="_blank">Matryoshka Representation Learning</a></li>
            <li><a href="https://arxiv.org/abs/2407.20798" target="_blank">Diffusion Augmented Agents: A Framework for Efficient Exploration and Transfer Learning</a></li>
            <li><a href="https://arxiv.org/abs/2407.12994" target="_blank">A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks</a></li>
            <li><a href="https://arxiv.org/abs/2404.06910" target="_blank">Superposition Prompting: Improving and Accelerating Retrieval-Augmented Generation</a></li>
            <li><a href="https://arxiv.org/abs/2408.14906" target="_blank">Writing in the Margins: Better Inference Pattern for Long Context Retrieval</a></li>
            <li><a href="https://arxiv.org/abs/2408.16357" target="_blank">Law of Vision Representation in MLLMs</a></li>
            <li><a href="https://arxiv.org/abs/2406.17262" target="_blank">D2LLM: Decomposed and Distilled Large Language Models for Semantic Search</a></li>
            <li><a href="https://arxiv.org/abs/2403.02078" target="_blank">Automated Generation of Multiple-Choice Cloze Questions for Assessing English Vocabulary Using GPT-turbo 3.5</a></li>
        </ul>
    </div>

    <!-- Second Block of List -->
    <div>
        <h2>Retrieval-Augmented Generation</h2>
        <ul>
            <li><a href="https://arxiv.org/abs/2402.14207" target="_blank">Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models</a></li>
            <li><a href="https://arxiv.org/abs/2407.16833" target="_blank">Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach</a></li>
            <li><a href="https://arxiv.org/abs/2407.01219" target="_blank">Searching for Best Practices in Retrieval-Augmented Generation</a></li>
            <li><a href="https://arxiv.org/abs/2406.17419" target="_blank">Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA</a></li>
            <li><a href="https://arxiv.org/abs/2406.12566" target="_blank">RichRAG: Crafting Rich Responses for Multi-faceted Queries in Retrieval-Augmented Generation</a></li>
            <li><a href="https://arxiv.org/abs/2310.01558" target="_blank">Making Retrieval-Augmented Language Models Robust to Irrelevant Context</a></li>
            <li><a href="https://arxiv.org/abs/2405.20978" target="_blank">Enhancing Noise Robustness of Retrieval-Augmented Language Models with Adaptive Adversarial Training</a></li>
            
        </ul>
    </div>

    <!-- Third Block of List -->
    <div>
        <h2>Optimize / Fine tune model</h2>
        <ul>
            <li><a href="https://arxiv.org/abs/2407.14679" target="_blank">Compact Language Models via Pruning and Knowledge Distillation</a></li>
            <li><a href="https://arxiv.org/abs/2407.16216" target="_blank">A Comprehensive Survey of LLM Alignment Techniques: RLHF, RLAIF, PPO, DPO and More</a></li>
            <li><a href="https://arxiv.org/abs/2405.12130" target="_blank">MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning</a></li>
            <li><a href="https://arxiv.org/abs/2304.11277" target="_blank">PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel</a></li>
            <li><a href="https://research.character.ai/optimizing-inference/" target="_blank">Optimizing AI Inference at Character.AI</a></li>
        </ul>
    </div>

    <!-- Fourth Block of List -->
    <div>
        <h2>VLM</h2>
        <ul>
            <li><a href="https://arxiv.org/abs/2406.09246" target="_blank">OpenVLA: An Open-Source Vision-Language-Action Model</a></li>
        </ul>
    </div>

    <!-- Fifth Block of List -->
    <div>
        <h2>Other</h2>
        <ul>
            <li><a href="https://arxiv.org/abs/2408.14837" target="_blank">Diffusion Models Are Real-Time Game Engines</a></li>
            <li><a href="https://arxiv.org/abs/2404.19756" target="_blank">KAN: Kolmogorov-Arnold Networks</a></li>
        </ul>
    </div>
</body>
</html>
